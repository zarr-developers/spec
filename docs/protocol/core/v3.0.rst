.. This file is in restructured text format: http://docutils.sourceforge.net/rst.html

==================================
 Zarr core protocol (version 3.0)
==================================
-----------------------------
 Editor's draft 19 June 2019
-----------------------------

Specification URI:
    https://purl.org/zarr/spec/protocol/core/3.0

Issue tracking:
    `GitHub issues <https://github.com/zarr-developers/zarr-specs/labels/core-protocol-v3.0>`_

Suggest an edit for this spec:
    `GitHub editor <https://github.com/zarr-developers/zarr-specs/blob/core-protocol-v3.0-dev/docs/protocol/core/v3.0.rst>`_

Copyright 2019 `Zarr core development
team <https://github.com/orgs/zarr-developers/teams/core-devs>`_ (@@TODO
list institutions?). This work is licensed under a `Creative Commons
Attribution 3.0 Unported
License <https://creativecommons.org/licenses/by/3.0/>`_.

----


Abstract
========

This specification defines the Zarr core protocol for storage and
retrieval of N-dimensional typed arrays.


Status of this document
=======================

This document is a **Work in Progress**. It may be updated, replaced
or obsoleted by other documents at any time. It is inappropriate to
cite this document as other than work in progress.

Comments, questions or contributions to this document are very
welcome. Comments and questions should be raised via `GitHub issues
<https://github.com/zarr-developers/zarr-specs/labels/core-protocol-v3.0>`_. When
raising an issue, please add the label
"core-protocol-v3.0". Contributions and suggested edits can be made
via GitHub via the `online editor
<https://github.com/zarr-developers/zarr-specs/blob/core-protocol-v3.0-dev/docs/protocol/core/v3.0.rst>`_
or by making a pull request against the
`"core-protocol-v3.0-dev" branch <https://github.com/zarr-developers/zarr-specs/tree/core-protocol-v3.0-dev>`_.

This document was produced by the `Zarr core development team
<https://github.com/orgs/zarr-developers/teams/core-devs>`_.


Document conventions
====================

Conformance requirements are expressed with a combination of
descriptive assertions and [RFC2119]_ terminology. The key words
"MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD",
"SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in the normative
parts of this document are to be interpreted as described in
[RFC2119]_. However, for readability, these words do not appear in all
uppercase letters in this specification.

All of the text of this specification is normative except sections
explicitly marked as non-normative, examples, and notes. Examples in
this specification are introduced with the words "for example".


Concepts and terminology
========================

This section introduces and defines some key terms and explains the
conceptual model underpinning the Zarr protocol.

.. _hierarchy:

*Hierarchy*

    A Zarr hierarchy is a tree structure, where each node in the tree
    is either a group_ or an array_. Group nodes may have children but
    array nodes may not. All nodes in a hierarchy have a name_ and a
    path_.

.. _group:
.. _groups:

*Group*

    A group is a node in a hierarchy_ that may have child nodes.

.. _array:
.. _arrays:

*Array*

    An array is a node in a hierarchy_. An array is a data structure
    with zero or more dimensions_ whose lengths define the shape_ of
    the array. An array contains zero or more data elements_. All
    elements_ in an array conform to the same `data type`_. An array
    may not have child nodes.

.. _name:
.. _names:

*Name*

    Each node in a hierarchy_ has a name, which is a string of
    characters with some additional constraints defined in the section
    on `node names`_ below. Two sibling nodes cannot have the same
    name. The root node does not have a name.

.. _path:
.. _paths:

*Path*

    Each node in a hierarchy_ has a path which uniquely identifies
    that node and defines its location within the hierarchy_. The path
    is formed by joining together the "/" character, followed by the
    name_ of each ancestor node separated by the "/" character,
    followed by the name_ of the node itself. For example, the path
    "/foo/bar" identifies a node named "bar", whose parent is named
    "foo", whose parent is the root of the hierarchy. The path "/"
    identifies the root node.

.. _dimension:
.. _dimensions:

*Dimension*

    An array_ has a fixed number of zero or more dimensions. Each
    dimension has an integer length. This specification only considers
    the case where the lengths of all dimensions are finite. However,
    `protocol extensions`_ may be defined which allow a dimension to have
    infinite or variable length.

.. _shape:

*Shape*

    The shape of an array_ is the tuple of dimension_ lengths. For
    example, if an array_ has 2 dimensions_, where the length of the
    first dimension_ is 100 and the length of the second dimension_ is
    20, then the shape of the array_ is (100, 20).

.. _element:
.. _elements:

*Element*

    An array_ contains zero or more elements. Each element can be
    identified by a tuple of integer coordinates, one for each
    dimension_ of the array_. If all dimensions_ of an array_ have
    finite length, then the number of elements in the array_ is given
    by the product of the dimension_ lengths. An array_ element may be
    empty, or it may have a value.

.. _data type:

*Data type*

    A data type defines the set of possible values that an array_ may
    contain, and a binary representation (i.e., sequence of bytes) for
    each possible value. For example, the little-endian 32-bit signed
    integer data type defines binary representations for all integers
    in the range âˆ’2,147,483,648 to 2,147,483,647. This specification
    only defines a limited set of data types, but protocol extensions
    may define other data types.

.. _chunk:
.. _chunks:

*Chunk*

    An array_ is divided into a set of chunks, where each chunk is a
    hyperrectangle defined by a tuple of intervals, one for each
    dimension_ of the array_. The chunk shape is the tuple of interval
    lengths, and the chunk size (i.e., number of elements_ contained
    within the chunk) is the product of its interval lengths.

.. _grid:
.. _grids:

*Grid*

    The chunks_ of an array_ are organised into a grid. This
    specification only considers the case where all chunks_ have the
    same chunk shape and the chunks form a regular grid. However,
    protocol extensions may define other grid types such as
    rectilinear grids.

.. _memory layout:
.. _memory layouts:

*Memory layout*

    An array_ is associated with a memory layout which defines how to
    construct a binary representation of a single chunk_ by organising
    the binary values of the elements_ within the chunk_ into a single
    contiguous sequence of bytes. This specification defines two types
    of memory layout based on "C" (row-major) and "F" (column-major)
    ordering of elements_, but protocol extensions may define other
    memory layouts.

.. _compressor:
.. _compressors:

*Compressor*

    An array_ may be associated with a compressor, which is a codec_
    that transforms the binary representation of a chunk_ in some way,
    usually to reduce data size.

.. _codec:
.. _codecs:

*Codec*

    A codec is a pair of algorithms which transform binary data in
    some way and are used to encode and decode chunks_. This
    specification defines a codec interface which comprises
    a pair of operations, one to perform the transformation (encode),
    the other to reverse the transformation (decode). This
    specification only considers the case where a codec is used as a
    compressor_, but protocol extensions may extend the chunk encoding
    process, for example, to add support for one or more filter codecs
    to be applied prior to compression.

.. _metadata document:
.. _metadata documents:

*Metadata document*

    Each node in a hierarchy_ is represented by a metadata document,
    which is a machine-readable document containing essential
    processing information about the node. For example, an array_
    metadata document will specify the number of dimensions_, shape_,
    `data type`_, grid_, `memory layout`_ and compressor_ for that
    array_.

.. _store:
.. _stores:

*Store*

    The `metadata documents`_ and encoded chunk_ data for all nodes in
    a hierarchy_ are held in a store. To enable a variety of different
    store types to be used, this specification defines an `Abstract store
    interface`_ which is a common set of operations that stores may
    provide.


Node names
==========

Except for the root node, each node in a hierarchy must have a name,
which is a string of ASCII characters. To ensure consistent behaviour
across different storage systems, the following constraints apply to
node names:

* must not be the empty string ("")

* must consist only of characters in the sets `a-z`, `A-Z`, `0-9`,
  `-_.`

* must not be a string composed only of period characters, e.g. "." or
  ".."

* must be at most 255 characters long

Note that node names are used to form storage keys, and that some
storage systems will perform a case-insensitive comparison of storage
keys during retrieval. Therefore, within a hierarchy, all nodes within
a set of sibling nodes must have a name that is unique under
case-insensitive comparison. E.g., the names "foo" and "FOO" are not
allowed for sibling nodes.


Data types
==========

A data type describes the set of possible binary values that an array
element may take, along with some information about how the values
should be interpreted.

This protocol defines a limited set of data types to represent Boolean
values, integers, floating point numbers and complex numbers. Protocol
extensions may define additional data types. All of the data types
defined here have a fixed size, in the sense that all values require
the same number of bytes. However, protocol extensions may define
variable sized data types.

Note that the Zarr protocol is intended to enable communication of
data between a variety of computing environments. The native byte
order may differ between machines used to write and read the data.

Each data type is associated with an identifier, which can be used in
metadata documents to refer to the data type. For the data types
defined in this protocol, the identifier is a simple ASCII
string. However, protocol extensions may use any JSON value to
identify a data type.


Core data types
---------------

.. list-table:: Data types
   :header-rows: 1

   * - Identifier
     - Numerical type
     - Size (no. bytes)
     - Byte order
   * - `bool`
     - Boolean, with False encoded as `\\x00` and True encoded as `\\x01`
     - 1
     - None
   * - `i1`
     - signed integer
     - 1
     - None
   * - `<i2`
     - signed integer
     - 2
     - little-endian
   * - `<i4`
     - signed integer
     - 4
     - little-endian
   * - `<i8`
     - signed integer
     - 8
     - little-endian
   * - `>i2`
     - signed integer
     - 2
     - big-endian
   * - `>i4`
     - signed integer
     - 4
     - big-endian
   * - `>i8`
     - signed integer
     - 8
     - big-endian
   * - `u1`
     - signed integer
     - 1
     - None
   * - `<u2`
     - unsigned integer
     - 2
     - little-endian
   * - `<u4`
     - unsigned integer
     - 4
     - little-endian
   * - `<u8`
     - unsigned integer
     - 8
     - little-endian
   * - `<f2`
     - half precision float: sign bit, 5 bits exponent, 10 bits mantissa
     - 2
     - little-endian
   * - `<f4`
     - single precision float: sign bit, 8 bits exponent, 23 bits mantissa
     - 4
     - little-endian
   * - `<f8`
     - double precision float: sign bit, 11 bits exponent, 52 bits mantissa
     - 8
     - little-endian
   * - `>f2`
     - half precision float: sign bit, 5 bits exponent, 10 bits mantissa
     - 2
     - big-endian
   * - `>f4`
     - single precision float: sign bit, 8 bits exponent, 23 bits mantissa
     - 4
     - big-endian
   * - `>f8`
     - double precision float: sign bit, 11 bits exponent, 52 bits mantissa
     - 8
     - big-endian

Floating point types correspond to basic binary interchange formats as
defined by IEEE 754-2008.


Chunk grids
===========

A chunk grid defines a set of chunks which contain the elements of an
array. The chunks of a grid form a tessellation of the array space,
which is a space defined by the dimensionality and shape of the
array. This means that every element of the array is a member of one
chunk, and there are no gaps or overlaps between chunks.

In general there are different possible types of grids. The core
protocol defines the regular grid type, where all chunks are
hyperrectangles of the same shape. Protocol extensions may define
other grid types, such as rectilinear grids where chunks are still
hyperrectangles but do not all share the same shape.

A grid type must also define rules for constructing an identifier for
each chunk that is unique within the grid, which is a string of ASCII
characters that can be used to construct keys to save and retrieve
chunk data in a store, see also the `Storage protocol`_ section.

Regular grids
-------------

A regular grid is a type of grid where an array is divided into chunks
such that each chunk is a hyperrectangle of the same shape. The
dimensionality of the grid is the same as the dimensionality of the
array. Each chunk in the grid can be addressed by a tuple of positive
integers (`i`, `j`, `k`, ...) corresponding to the indices of the
chunk along each dimension.

The origin vertex of a chunk has coordinates in the array space (`i` *
`dx`, `j` * `dy`, `k` * `dz`, ...) where (`dx`, `dy`, `dz`, ...) are
the grid spacings along each dimension, also known as the chunk
shape. Thus the origin vertex of the chunk at grid index (0, 0, 0,
...) is at coordinate (0, 0, 0, ...) in the array space, i.e., the
grid is aligned with the origin of the array. If the length of any
array dimension is not perfectly divisible by the chunk length along
the same dimension, then the grid will overhang the edge of the array
space.

The shape of the chunk grid will be (ceil(`x` / `dx`), ceil(`y` /
`dy`), ceil(`z` / `dz`), ...)  where (`x`, `y`, `z`, ...) is the array
shape, "/" is the division operator and "ceil" is the ceiling
function. For example, if a 3 dimensional array has shape (10, 200,
3000), and has chunk shape (5, 20, 400), then the shape of the chunk
grid will be (2, 10, 8), meaning that there will be 2 chunks along the
first dimension, 10 along the second dimension, and 8 along the third
dimension.

An element of an array with coordinates (`a`, `b`, `c`, ...) will
occur within the chunk at grid index (`a` // `dx`, `b` // `dy`, `c` //
`dz`, ...), where "//" is the floor division operator. The element
will have coordinates (`a` % `dx`, `b` % `dy`, `c` % `dz`, ...) within
that chunk, where "%" is the modulo operator. For example, if a 
3 dimensional array has shape (10, 200, 3000), and has chunk shape
(5, 20, 400), then the element of the array with coordinates (7, 150, 900)
is contained within the chunk at grid index (1, 7, 2) and has coordinates
(2, 10, 100) within that chunk.

The identifier for chunk with grid index (`i`, `j`, `k`, ...) is
formed by joining together ASCII string representations of each index
using a separator. The default value for the separator is the period
character ("."), but this may be configured by providing a ``separator``
value within the ``chunk_grid`` metadata object, see the section on
`Array metadata`_ below.

For example, in a 3 dimensional array, the identifier for the chunk at
grid index (1, 23, 45) is the string "1.23.45".

Note that this specification does not consider the case where the
chunk grid and the array space are not aligned at the origin vertices
of the array and the chunk at grid index (0, 0, 0, ...). However,
protocol extensions may define variations on the regular grid type
such that the grid indices may include negative integers, and the
origin vertex of the array may occur at an arbitrary position within
any chunk, which is required to allow arrays to be extended by an
arbitrary length in a "negative" direction along any dimension.


Chunk memory layouts
====================

An array has a memory layout, which defines the way that the binary
values of the array elements are organised within each chunk to form a
contiguous sequence of bytes. This contiguous binary representation of
a chunk is then the input to the array's chunk encoding pipeline,
described in later sections. Typically, when reading data, an
implementation will load this binary representation into a contiguous
memory buffer to allow direct access to array elements without having
to copy data.

The core protocol defines two types of contiguous memory
layout. However, protocol extensions may define other memory
layouts. Note that there may be an interdependency between memory
layouts and data types, such that certain memory layouts may only be
applicable to arrays with certain data types.

C contiguous memory layout
--------------------------

In this memory layout, the binary values of the array elements are
organised into a sequence such that the last dimension of the array is
the fastest changing dimension, also known as "row-major" order. This
layout is only applicable to arrays with fixed size data types.

For example, for a two-dimensional array with chunk shape (`dx`, `dy`),
the binary values for a given chunk are taken from chunk elements in
the order (0, 0), (0, 1), (0, 2), ..., (`dx` - 1, `dy` - 3), (`dx` - 1, `dy` -
2), (`dx` - 1, `dy` - 1).

F contiguous memory layout
--------------------------

In this memory layout, the binary values of the array elements are
organised into a sequence such that the first dimension of the array
is the fastest changing dimension, also known as "column-major"
order. This layout is only applicable to arrays with fixed size data
types.

For example, for a two-dimensional array with chunk shape (`dx`,
`dy`), the binary values for a given chunk are taken from chunk
elements in the order (0, 0), (1, 0), (2, 0), ..., (`dx` - 3, `dy` -
1), (`dx` - 2, `dy` - 1), (`dx` - 1, `dy` - 1).


Chunk encoding
==============

An array may be configured with a compressor, which a codec used to
transform the binary representation of each chunk prior to storage,
and to reverse the transformation during retrieval.

@@TODO better explanation of chunk encoding

A codec is defined as a pair of algorithms named *encode* and
*decode*. Both of these algorithms transform a sequence of bytes
(input) into another sequence of bytes (output). The *decode*
algorithm is the reverse of the *encode* algorithm, but it is not
required that the reversal is perfect. For example, a codec may be a
lossy compressor for floating point data, which will lose some
numerical precision during encoding and thus not reproduce exactly the
original byte sequence after subsequent decoding. However, if *a* is
the binary representation of a chunk with data type *d* and internal
memory layout *m*, then the result *b = decode(encode(a))* must be
consistent with the data type and memory layout of *a*.

To allow for flexibility to define and implement new codecs, this
specification does not define any codecs, nor restrict the set of
codecs that may be used. Each codec must be defined via a separate
specification. In order to refer to codecs in array metadata
documents, each codec must have a unique identifier, which is a URI
that dereferences to a human-readable specification of the codec. A
codec specification must declare the codec identifier, and describe
(or cite documents that describe) the encoding and decoding algorithms
and the format of the encoded data.

A codec may have configuration parameters which modify the behaviour
of the codec in some way. For example, a compression codec may have a
compression level parameter, which is an integer that affects the
resulting compression ratio of the data. Configuration parameters must
be declared in the codec specification, including a definition of how
configuration parameters are represented as JSON.

The Zarr core development team maintains a repository of codec
specifications, which are hosted alongside this specification in the
`zarr-specs GitHub repository
<https://github.com/zarr-developers/zarr-specs>`_, and which are
published on the `zarr-specs documentation Web site
<http://zarr-specs.readthedocs.io/>`_. For ease of discovery, it is
recommended that codec specifications are contributed to the
zarr-specs GitHub repository. However, codec specifications may be
maintained by any group or organisation and published in any location
on the Web. For further details of the process for contributing a
codec specification to the zarr-specs GitHub repository, see the Zarr
community process specification @@TODO Add link once
https://github.com/zarr-developers/zarr-specs/pull/12 is merged@@.

Further details of how a compressor is configured for an array are
given in the section below on `Array metadata`_.


Metadata
========

This section defines the structure of metadata documents for Zarr
arrays and groups. Metadata documents are defined here using the JSON
type system defined in [RFC8259]_. In this section, the terms "value",
"number", "string" and "object" are used to denote the types as
defined in [RFC8259]_. The term "array" is also used as defined in
[RFC8259]_, except where qualified as "Zarr array". Following
[RFC8259]_, this section also describes an object as a set of
name/value pairs.

This section also defines how metadata documents are encoded for
storage. The canonical encoding is JSON, however any other encoding
which supports an equivalent type system may be used for array and
group metadata documents.

Bootstrap metadata
------------------

@@TODO should this be called "entry-point metadata"? Or something
else?

Each Zarr hierarchy must have a bootstrap metadata document, which
provides essential information regarding the protocol version being
used, the encoding being used for group and array metadata, and any
protocol extensions that affect the layout or interpretation of data
in the store.

The bootstrap metadata document must contain a single object
containing the following names:

``zarr_format``

    A string containing the URI of the Zarr core protocol
    specification that defines the metadata format. For Zarr
    hierarchies conforming to this specification, the value must be
    the string "https://purl.org/zarr/spec/protocol/core/3.0".

    Implementations of this protocol may assume that the final path
    segment of this URI ("3.0") represents the core protocol version
    number, where "3" is the major version number and "0" is the minor
    version number. Implementations of this protocol may also assume
    that future versions of this protocol that retain the same major
    versioning number ("3") will be backwards-compatible, in the sense
    that any new features added to the protocol can be safely
    ignored. In other words, if the major version number is "3",
    implementations of this protocol may read and interpret metadata
    as defined in this specification, ignoring any name/value pairs
    where the name is not defined here.

    Note that this value is given as a URI rather than as a simple
    version number string to help with discovery of this
    specification.

``metadata_encoding``

    A string containing the MIME type that has been used for encoding
    group and array metadata documents. If JSON encoding is used, this
    value must be "application/json".

``extensions``

    An array containing zero or more objects, each of which identifies
    a protocol extension and provides any additional extension
    configuration metadata. Each object must contain the name
    ``extension`` whose value is a URI that identifies a Zarr protocol
    extension and dereferences to a human readable representation of
    the extension specification. Each object must also contain the
    name ``must_understand`` whose value is either the literal
    ``true`` or ``false``. Each object may also contain the name
    ``configuration`` whose value is defined by the protocol
    extension.

    If an implementation of this specification encounters an extension
    that it does not recognise, but the value of ``must_understand``
    is ``false``, then the extension may be ignored and processing may
    continue. If the extension is not recognised and the value of
    ``must_understand`` is ``true`` then processing must terminate and
    an appropriate error raised.

For example, below is a bootstrap metadata document, specifying that
JSON is being used for encoding of group and array metadata::

    {
        "zarr_format": "https://purl.org/zarr/spec/protocol/core/3.0",
        "metadata_encoding": "application/json",
        "extensions": []
    }

For example, below is a bootstrap metadata document as above, but also
specifying that a protocol extension is being used which may be
ignored if not understood::

    {
        "zarr_format": "https://purl.org/zarr/spec/protocol/core/3.0",
        "metadata_encoding": "application/json",
        "extensions": [
            {
                "extension": "http://example.org/zarr/extension/foo",
                "must_understand": false,
                "configuration": {
                    "foo": "bar"
                }
            }
        ]
    }


Array metadata
--------------

Each Zarr array in a hierarchy must have an array metadata
document. This document must contain a single object with the
following names:

``shape``

    An array of integers providing the length of each dimension of the
    Zarr array. For example, a value ``[10, 20]`` indicates a
    two-dimensional Zarr array, where the first dimension has length
    10 and the second dimension has length 20.

``data_type``

    The data type of the Zarr array. If the data type is defined in
    this specification, then the value must be the data type
    identifier provided as a string. For example, ``"<f8"`` for
    little-endian 64-bit floating point number.

    The ``data_type`` value is an extension point and may be defined
    by a protocol extension. If the data type is defined by a protocol
    extension, then the value must be an object containing the names
    ``extension``, ``type`` and ``fallback``. The ``extension`` is
    required and its value must be a URI that identifies the protocol
    extension and dereferences to a human-readable representation of
    the specification.  The ``type`` is required and its value is
    defined by the protocol extension. The ``fallback`` is optional
    and, if provided, its value must be one of the data type
    identifiers defined in this specification. If an implementation
    does not recognise the extension, but a ``fallback`` is present,
    then the implementation may proceed using the ``fallback`` value
    as the data type.

``chunk_grid``

    The chunk grid of the Zarr array. If the chunk grid is a regular
    chunk grid as defined in this specification, then the value must
    be an object with the names ``type`` and ``chunk_shape``. The
    value of ``type`` must be the string "regular", and the value of
    ``chunk_shape`` must be an array of integers providing the lengths
    of the chunk along each dimension of the array. For example,
    ``{"type": "regular", "chunk_shape": [2, 5]}`` means a regular
    grid where the chunks have length 2 along the first dimension and
    length 5 along the second dimension.

    The ``chunk_grid`` value is an extension point and may be defined
    by a protocol extension. If the chunk grid type is defined by a
    protocol extension, then the value must be an object containing
    the names ``extension`` and ``type``. The ``extension`` is
    required and the value must be a URI that identifies the protocol
    extension and dereferences to a human-readable representation of
    the specification.  The ``type`` is required and the value is
    defined by the protocol extension.

``chunk_memory_layout``

    The internal memory layout of the chunks. Use the value "C" to
    indicate `C contiguous memory layout`_ or "F" to indicate
    `F contiguous memory layout`_ as defined in this specification.

    The ``chunk_memory_layout`` value is an extension point and may be
    defined by a protocol extension. If the chunk memory layout type
    is defined by a protocol extension, then the value must be an
    object containing the names ``extension`` and ``type``. The
    ``extension`` is required and the value must be a URI that
    identifies the protocol extension and dereferences to a
    human-readable representation of the specification.  The ``type`` is
    required and the value is defined by the protocol extension.

``compressor``

    Specifies a codec to be used for encoding and decoding chunks. The
    value must be an object containing the name ``codec`` whose value
    is a URI that identifies a codec and dereferences to a human
    readable representation of the codec specification. The codec
    object may also contain a ``configuration`` name whose value is
    defined by the corresponding codec specification.

``fill_value``

    Provides an element value to use for uninitialised portions of the
    Zarr array.

    If the data type of the Zarr array is Boolean then the value must
    be the literal ``false`` or ``true``. If the data type is one of
    the integer data types defined in this specification, then the
    value must be a number with no fraction or exponent part and must
    be within the range of the data type. TODO what about floating
    point data types? TODO what about complex data types? TODO what
    about nan and inf? TODO what about extension data types?

    For any data type, if the ``fill_value`` is the literal ``null``
    then the fill value is undefined and the implementation may use
    any arbitrary value that is consistent with the data type as the
    fill value.

``extensions``

    The value @@TODO

``attributes``

    The value must be an object. The object may contain any name/value
    pairs.

All other names within the array metadata object are reserved for
future versions of this specification.

For example, the array metadata document below defines a
two-dimensional array of 64-bit little-endian floating point numbers,
with 10000 and 1000 columns, divided into a regular chunk grid where
each chunk has 1000 rows and 100 columns, and thus there will be 100
chunks in total arranged into a 10 by 10 grid. Within each chunk the
binary values are laid out in C contiguous order. Each chunk is
compressed using gzip compression prior to storage::

    {
        "shape": [10000, 1000],
        "data_type": "<f8",
        "chunk_grid": {
            "type": "regular",
            "chunk_shape": [1000, 100]
        },
        "chunk_memory_layout": "C",
        "compressor": {
            "codec": "http://purl.org/zarr/spec/codec/gzip",
            "configuration": {
                "level": 1
            }
        },
        "fill_value": "NaN",
        "extensions": [],
        "attributes": {
            "foo": 42,
            "bar": "apples",
            "baz": [1, 2, 3, 4]
        }
    }

The following example illustrates an array with the same shape and
chunking as above, but using an extension data type::

    {
        "shape": [10000, 1000],
        "data_type": {
            "extension": "http://purl.org/zarr/spec/protocol/extensions/datetime-dtypes/1.0",
            "type": "<M8[ns]",
            "fallback": "<i8"
        },
        "chunk_grid": {
            "type": "regular",
            "chunk_shape": [1000, 100]
        },
        "chunk_memory_layout": "C",
        "compressor": {
            "codec": "http://purl.org/zarr/spec/codec/gzip",
            "configuration": {
                "level": 1
            }
        },
        "fill_value": null,
        "extensions": [],
        "attributes": {}
    }


Group metadata
--------------

A Zarr group metadata object must contain the `extensions` and `attributes`
names as defined above. All other names
are reserved for future versions of this
specification. See also the section
on `Protocol extensions`_ below.

For example, the JSON document below defines a group::

    {
        "extensions": [],
        "attributes": {
            "spam": "ham",
            "eggs": 42,
        }
    }


Metadata encoding
-----------------

The bootstrap metadata document must be encoded as JSON. The array and
group metadata documents must be encoded as per the MIME type given in
the ``metadata_encoding`` field in the bootstrap metadata document.

@@TODO more explanation needed?


Stores
======

A Zarr store is a system that can be used to store and retrieve data
from a Zarr hierarchy. For a store to be compatible with this
protocol, it must support a set of operations defined in the `Abstract store
interface`_ subsection. The store interface can be implemented using a
variety of underlying storage technologies, described in the
subsection on `Store implementations`_.

Abstract store interface
------------------------

The store interface is intended to be simple to implement using a
variety of different underlying storage technologies. It is defined in
a general way here, but it should be straightforward to translate into
a software interface in any given programming language. The goal is
that an implementation of this specification could be modular and
allow for different store implementations to be used.

The store interface defines a set of operations involving `keys` and
`values`. In the context of this interface, a `key` is any ASCII
string containing only characters in the ranges ``a-z``, ``A-Z``,
``0-9``, or in the set ``/.-_``, and a `value` is any sequence of
bytes. It is assumed that the store holds (`key`, `value`) pairs, with
only one such pair for any given `key`. I.e., a store is a mapping
from keys to values.

The store operations are grouped into three sets of capabilities:
**readable**, **writeable** and **listable**. It is not necessary for
a store implementation to support all of these capabilities.

A **readable store** supports the following operation:

``get`` - Retrieve the `value` associated with a given `key`.

    | Parameters: `key`
    | Output: `value`

A **writeable store** supports the following operations:

``set`` - Store a (`key`, `value`) pair.

    | Parameters: `key`, `value`
    | Output: none

``delete`` - Delete the given key/value pair from the store.

    | Parameters: `key`
    | Output: none

A **listable store** supports any one or more of the following
operations:

``list`` - Retrieve all `keys` in the store.

    | Parameters: none
    | Output: set of `keys`

``list_prefix`` - Retrieve all keys with a given prefix.

    | Parameters: `prefix`
    | Output: set of `keys` with the given `prefix`

    For example, if a store contains the keys "a/b", "a/c/d" and
    "e/f/g", then ``list_prefix("a/")`` would return "a/b" and "a/c/d".

``list_dir`` - Retrieve all keys and prefixes with a given prefix and
which do not contain "/" after the given prefix.

    | Parameters: `prefix`
    | Output: set of `keys` and set of `prefixes`

    For example, if a store contains the keys "a/b", "a/c", "a/d/e",
    "a/f/g", then ``list_dir("a/")`` would return keys "a/b" and "a/c"
    and prefixes "a/d/" and "a/f/".


Store implementations
---------------------

(This subsection is not normative.)

A store implementation maps the abstract operations of the store
interface onto concrete operations on some underlying storage
system. This specification does not constrain or make any assumptions
about the nature of the underlying storage system. Thus it is possible
to implement the store interface in a variety of different ways.

For example, a store implementation might use a conventional file
system as the underlying storage system, mapping keys onto file paths
and values onto file contents. The ``get`` operation could then be
implemented by reading a file, the ``set`` operation implemented by
writing a file, and the ``list_dir`` operation implemented by listing
a directory.

For example, a store implementation might use a key-value database
such as BerkeleyDB or LMDB as the underlying storage system. In this
case the implementation of ``get`` and ``set`` operations would be
obvious, being whatever are the native operations provided by the
database for getting and setting key/value pairs. Such a store
implementation might natively support the ``list`` operation but might
not support ``list_prefix`` or ``list_dir``, although these could be
implemented via ``list`` with post-processing of the returned keys.

For example, a store implementation might use a cloud object storage
service such as Amazon S3, Azure Blob Storage, or Google Cloud Storage
as the underlying storage system, mapping keys to object names and
values to object contents. The store interface operations would then
be implemented via concrete operations of the service's REST API,
i.e., via HTTP requests. E.g., the ``get`` operation could be
implemented via an HTTP GET request to an object URL, the ``set``
operation could be implemented via an HTTP PUT request to an object
URL, and the list operations could be implemented via an HTTP GET
request to a bucket URL (i.e., listing a bucket).

The examples above are meant to be illustrative only, and other
implementations are possible. This specification does not attempt to
standardise any store implementations, however where a store
implementation is expected to be widely used then it is recommended to
create a store implementation spec and contribute it to the zarr-specs
GitHub repository. @@TODO more info and example.


Storage protocol
================

This section describes how to translate high level operations to
create, delete or modify Zarr hierarchies, groups or arrays, into low
level operations on the key/value store interface defined above.

In this section a "hierarchy path" is a logical path which identifies
a group or array node within a Zarr hierarchy, and a "storage key" is
a key used to store and retrieve data via the store interface. There
is a further distinction between "metadata keys" which are storage
keys used to store metadata documents, and "chunk keys" which are
storage keys used to store encoded chunks.

Note that any non-root hierarchy path will have ancestor paths that
identify ancestor nodes in the hierarchy. For example, the path
"/foo/bar" has ancestor paths "/foo" and "/".

Storage keys
------------

The bootstrap metadata document is stored under the key "zarr.json".

For a group at a non-root hierarchy path `P`, the metadata key for the
group metadata document is formed by concatenating "meta/root", `P`,
and ".group".

For example, for a group at hierarchy path "/foo/bar", the
corresponding metadata key is "meta/root/foo/bar.group".

For an array at a non-root hierarchy path `P`, the metadata key for
the array metadata document is formed by concatenating "meta", `P`,
and ".array". The data key for array chunks is formed by concatenating
"data", `P`, "/", and the chunk identifier as defined by the chunk
grid layout.

For example, for an array at hierarchy path "/foo/baz", the
corresponding metadata key is "meta/root/foo/baz.array". If the array
has two dimensions and a regular chunk grid, the data key for the
chunk with grid coordinates (0, 0) is "data/foo/baz/0.0".

If the root node is a group, the metadata key is "meta/root.group". If
the root node is an array, the metadata key is "meta/root.array", and
the data keys are formed by concatenating "data/" and the chunk
identifier.


Protocol operations
-------------------

Let `P` be an arbitrary hierarchy path.

Let ``array_meta_key(P)`` be the array metadata key for `P`. Let
``group_meta_key(P)`` be the group metadata key for `P`.

Let ``data_key(P, i, j, ...)`` be the data key for `P` for the chunk
with grid coordinates (i, j, ...).

Let "+" be the string concatenation operator.

**Create a group**

    To create a group at hierarchy path `P`, perform
    ``set(group_meta_key(P), value)``, where `value` is the
    serialisation of a valid group metadata document.

    If `P` is a non-root path then it is **not** necessary to create
    or check for the existence of metadata documents for groups at any
    of the ancestor paths of `P`. Creating a group at path `P` implies
    the existence of groups at all ancestor paths of `P`.

**Create an array**

    To create an array at hierarchy path `P`, perform
    ``set(array_meta_key(P), value)``, where `value` is the
    serialisation of a valid array metadata document.

    If `P` is a non-root path then it is **not** necessary to create
    or check for the existence of metadata documents for groups at any
    of the ancestor paths of `P`. Creating an array at path `P`
    implies the existence of groups at all ancestor paths of `P`.

**Store element values in an array**

    @@TODO

**Retrieve element values in an array**

    @@TODO

**Discover children of a group**

    To discover the children of a group at hierarchy path `P`, perform
    ``list_dir("meta/root" + P + "/")``. Any returned key ending in
    ".array" indicates an array. Any returned key ending in
    ".group" indicates a group. Any returned prefix indicates a
    child group implied by some descendant.

    For example, if a group is created at path "/foo/bar" and an array
    is created at path "/foo/baz/qux", then the store will contain the
    keys "meta/root/foo/bar.group" and "meta/root/foo/bar/baz/qux.array". Groups
    at paths "/", "/foo" and "/foo/baz" have not been explicitly
    created but are implied by their descendants. To list the children
    of the group at path "/foo", perform ``list_dir("meta/root/foo/")``,
    which will return the key "meta/root/foo/bar.group" and the prefix
    "meta/root/foo/baz/". From this it can be inferred that child groups
    "/foo/bar" and "/foo/baz" are present.

    If a store does not support any of the list operations then
    discovery of group children is not possible, and the contents of
    the hierarchy must be communicated by some other means, such as
    via a protocol extension, or via some out of band communication.

**Discover all nodes in a hierarchy**

    @@TODO

**Delete a group or array**

    @@TODO

**Determine if a node exists**

    @@TODO


@@TODO need to describe/explain implicit groups more?


Protocol extensions
===================

TODO define different types of protocol extension.


References
==========

.. [RFC8259] T. Bray, Ed. The JavaScript Object Notation (JSON) Data
   Interchange Format. December 2017. Best Current Practice. URL:
   https://tools.ietf.org/html/rfc8259

.. [RFC2119] S. Bradner. Key words for use in RFCs to Indicate
   Requirement Levels. March 1997. Best Current Practice. URL:
   https://tools.ietf.org/html/rfc2119


Change log
==========

This section is a placeholder for keeping a log of the snapshots of
this document that are tagged in GitHub and what changed between them.

@@tag@@
-------

Links: `view spec
<https://zarr-specs.readthedocs.io/en/@@tag@@/protocol/core/v3.0.html>`_;
`view source
<https://github.com/zarr-developers/zarr-specs/blob/@@tag@@/docs/protocol/core/v3.0.rst>`_

@@TODO summary of changes since previous tag.
